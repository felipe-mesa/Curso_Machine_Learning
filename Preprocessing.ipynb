{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "version": "3.7.1-final"
    },
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "kernelspec": {
      "name": "python37132bitaea5f204258446b5830b7bd2f7875fbc",
      "display_name": "Python 3.7.1 32-bit"
    },
    "colab": {
      "name": "Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felipe-mesa/Curso_Machine_Learning/blob/master/Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhq5zg4zIaqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wENbmQwWIary",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv('Data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1VftztDIas-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Separa el dataset en una matriz X de variables independientes y un vector y de la variable dependiente\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, 3].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKC5s55_Iatl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#IMPUTADOR PARA DATOS FALTANTES\n",
        "from sklearn.impute import SimpleImputer\n",
        "#Selecciona un imputador que reemplaza los datos faltantes por la media de la columna\n",
        "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
        "#Se ajusta un imputador a toda la matriz con las variables independientes SOLO en las columnas donde hay datos faltantes\n",
        "imputer = imputer.fit(X[:, 1:3])\n",
        "#Se hace la transformaci√≥n reemplazando el dato faltante por la media de la columna\n",
        "X[:, 1:3] = imputer.transform(X[:, 1:3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQy-P-QwIauT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####CONVERTIR VARIABLES CATEGORICAS A NUMEROS####\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "#PARA MAS DE 2 VARIABLES CATEGORICAS\n",
        "#Captar las categorias y asignar numeros\n",
        "labelencoder_X = LabelEncoder()\n",
        "\n",
        "#Poner los numeros de las categorias en la matriz (problema: una categoria no puede ser mayor que otra, hay que usar variables binarias) \n",
        "X[:, 0] = labelencoder_X.fit_transform(X[:, 0])\n",
        "\n",
        "#Transforma los numeros de la variable categorica \"Country\", columna [0], en 3 variables binarias\n",
        "ct = ColumnTransformer([(\"Country\", OneHotEncoder(), [0])], remainder = 'passthrough')\n",
        "\n",
        "#Agrega las variables binarias a la matriz\n",
        "X = ct.fit_transform(X)\n",
        "\n",
        "\n",
        "#PARA 2 VARIABLES CATEGORICAS\n",
        "#Capta las variables categoricas y asigna variables binarias\n",
        "label_encoder_Y = LabelEncoder()\n",
        "\n",
        "#Escribe las variables binarias\n",
        "y = label_encoder_Y.fit_transform(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAKgqTA9J-sA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###DIVIDIR EL SET EN TRAINING SET Y TEST SET\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8yTNehrPilM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FEATURE SCALING (ESCALADOR)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#Calcula media y std y la aplica al dataset, no a las variables dummy\n",
        "sc = StandardScaler()\n",
        "\n",
        "#(Recordar que X_train es un arreglo numpy)\n",
        "X_train[:, 3:]  = sc.fit_transform(X_train[:, 3:])\n",
        "#Hay que usar el mismo escalador en el train set y el test set, NO hay que usar fit ya que se hizo un fit en el train set\n",
        "X_test[:, 3:]  = sc.transform(X_test[:, 3:])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}